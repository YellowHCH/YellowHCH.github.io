<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ch_huang</title>
    <link>https://yellowhch.github.io/</link>
    <description>Recent content on ch_huang</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 24 Dec 2023 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://yellowhch.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>How does xla integrate with triton</title>
      <link>https://yellowhch.github.io/post/how-does-xla-integrate-triton/</link>
      <pubDate>Sun, 24 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yellowhch.github.io/post/how-does-xla-integrate-triton/</guid>
      <description>Brief xla的codegen可以选择使用triton backend 对少量的op进行codegen，包括matmul和softmax。 通过选项xla_gpu_</description>
    </item>
    
    <item>
      <title>Inductor code review</title>
      <link>https://yellowhch.github.io/post/inductor-code-review/</link>
      <pubDate>Tue, 19 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yellowhch.github.io/post/inductor-code-review/</guid>
      <description>compile_fx dynamo 注册 inductor 主入口是 compile_fx 函数，在dynamo中 @register_backend def inductor(*args, **kwargs): # do import here to avoid loading inductor into memory when it is not used from torch._inductor.compile_fx import compile_fx return compile_fx(*args, **kwargs) compile_fx 核心逻辑 函数声明 def compile_fx( model_: torch.fx.GraphModule, example_inputs_: List[torch.Tensor], inner_compile: Callable[..., Any] = compile_fx_inner, config_patches: Optional[Dict[str, Any]]</description>
    </item>
    
    <item>
      <title>Analysis triton tutorial matmul L2 cache optimization</title>
      <link>https://yellowhch.github.io/post/analysis-triton-tutorial-matmul-opt-l2cache/</link>
      <pubDate>Fri, 15 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>https://yellowhch.github.io/post/analysis-triton-tutorial-matmul-opt-l2cache/</guid>
      <description>Ref to triton tutorial triton compiler 负责CTA内部的线程排布以及内存排布，CTA外部（即如何排布CTA）是由使用者去tune的。这篇triton的教程介绍了如何提高</description>
    </item>
    
  </channel>
</rss>